{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5407,"databundleVersionId":868283,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport pandas as pd\nimport numpy as np\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Ignore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-21T12:51:46.857004Z","iopub.execute_input":"2025-06-21T12:51:46.857233Z","iopub.status.idle":"2025-06-21T12:51:49.572367Z","shell.execute_reply.started":"2025-06-21T12:51:46.857188Z","shell.execute_reply":"2025-06-21T12:51:49.571540Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the dataset\ndf = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')  # Replace with your actual file name if it's different\n\n# Check shape and first few rows\nprint(\"Shape of the dataset:\", df.shape)\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T12:53:56.391788Z","iopub.execute_input":"2025-06-21T12:53:56.392363Z","iopub.status.idle":"2025-06-21T12:53:56.461023Z","shell.execute_reply.started":"2025-06-21T12:53:56.392335Z","shell.execute_reply":"2025-06-21T12:53:56.460304Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check missing values\nmissing_values = df.isnull().sum()\nmissing_values = missing_values[missing_values > 0].sort_values(ascending=False)\nprint(\"Columns with missing values:\\n\", missing_values)\n\n# Check data types\nprint(\"\\nData types of columns:\\n\")\nprint(df.dtypes.value_counts())\ndf.dtypes\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T12:54:33.090218Z","iopub.execute_input":"2025-06-21T12:54:33.090486Z","iopub.status.idle":"2025-06-21T12:54:33.106325Z","shell.execute_reply.started":"2025-06-21T12:54:33.090464Z","shell.execute_reply":"2025-06-21T12:54:33.105550Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Drop 'Id' since it doesn't carry predictive information\ndf.drop(columns=['Id'], inplace=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T12:57:15.438790Z","iopub.execute_input":"2025-06-21T12:57:15.439364Z","iopub.status.idle":"2025-06-21T12:57:15.447117Z","shell.execute_reply.started":"2025-06-21T12:57:15.439334Z","shell.execute_reply":"2025-06-21T12:57:15.446402Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Target column\ntarget = 'SalePrice'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T12:59:03.396385Z","iopub.execute_input":"2025-06-21T12:59:03.396864Z","iopub.status.idle":"2025-06-21T12:59:03.400306Z","shell.execute_reply.started":"2025-06-21T12:59:03.396838Z","shell.execute_reply":"2025-06-21T12:59:03.399414Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Separate features by datatype\nnumerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\ncategorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T12:59:33.721126Z","iopub.execute_input":"2025-06-21T12:59:33.721441Z","iopub.status.idle":"2025-06-21T12:59:33.727438Z","shell.execute_reply.started":"2025-06-21T12:59:33.721418Z","shell.execute_reply":"2025-06-21T12:59:33.726642Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"numerical_cols.remove(target)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T12:59:37.281800Z","iopub.execute_input":"2025-06-21T12:59:37.282484Z","iopub.status.idle":"2025-06-21T12:59:37.286341Z","shell.execute_reply.started":"2025-06-21T12:59:37.282453Z","shell.execute_reply":"2025-06-21T12:59:37.285509Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Numerical features:\", len(numerical_cols))\nprint(\"Categorical features:\", len(categorical_cols))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T12:59:55.716357Z","iopub.execute_input":"2025-06-21T12:59:55.716881Z","iopub.status.idle":"2025-06-21T12:59:55.720956Z","shell.execute_reply.started":"2025-06-21T12:59:55.716855Z","shell.execute_reply":"2025-06-21T12:59:55.720143Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fill missing numerical values with median\nfor col in numerical_cols:\n    if df[col].isnull().sum() > 0:\n        df[col].fillna(df[col].median(), inplace=True)\n# Fill missing categorical values with 'Missing'\nfor col in categorical_cols:\n    if df[col].isnull().sum() > 0:\n        df[col].fillna('Missing', inplace=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T13:00:34.878430Z","iopub.execute_input":"2025-06-21T13:00:34.878952Z","iopub.status.idle":"2025-06-21T13:00:34.907037Z","shell.execute_reply.started":"2025-06-21T13:00:34.878928Z","shell.execute_reply":"2025-06-21T13:00:34.906383Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check if any missing values remain\nprint(\"Any missing values left?\", df.isnull().sum().sum() > 0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T13:00:51.439514Z","iopub.execute_input":"2025-06-21T13:00:51.440223Z","iopub.status.idle":"2025-06-21T13:00:51.448762Z","shell.execute_reply.started":"2025-06-21T13:00:51.440180Z","shell.execute_reply":"2025-06-21T13:00:51.447988Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# One-hot encode categorical variables\ndf_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n\nprint(\"New shape after encoding:\", df_encoded.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T13:01:39.056624Z","iopub.execute_input":"2025-06-21T13:01:39.056894Z","iopub.status.idle":"2025-06-21T13:01:39.092077Z","shell.execute_reply.started":"2025-06-21T13:01:39.056872Z","shell.execute_reply":"2025-06-21T13:01:39.091482Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n# Separate features and target\nX = df_encoded.drop('SalePrice', axis=1)\ny = df_encoded['SalePrice']\n\n# Standardize the feature matrix\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\nprint(\"Shape after scaling:\", X_scaled.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T13:02:15.623970Z","iopub.execute_input":"2025-06-21T13:02:15.624765Z","iopub.status.idle":"2025-06-21T13:02:15.812462Z","shell.execute_reply.started":"2025-06-21T13:02:15.624734Z","shell.execute_reply":"2025-06-21T13:02:15.811650Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Apply PCA without limiting components\npca = PCA()\nX_pca = pca.fit_transform(X_scaled)\n\n# Plot explained variance ratio\nplt.figure(figsize=(10, 6))\nplt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o')\nplt.xlabel('Number of Principal Components')\nplt.ylabel('Cumulative Explained Variance')\nplt.title('Explained Variance vs Number of Components')\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T13:02:40.956714Z","iopub.execute_input":"2025-06-21T13:02:40.957002Z","iopub.status.idle":"2025-06-21T13:02:41.545817Z","shell.execute_reply.started":"2025-06-21T13:02:40.956978Z","shell.execute_reply":"2025-06-21T13:02:41.545118Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Keep 95% of variance\npca = PCA(n_components=0.95)\nX_reduced = pca.fit_transform(X_scaled)\n\nprint(\"Reduced shape after PCA:\", X_reduced.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T13:03:30.100797Z","iopub.execute_input":"2025-06-21T13:03:30.101349Z","iopub.status.idle":"2025-06-21T13:03:30.178006Z","shell.execute_reply.started":"2025-06-21T13:03:30.101323Z","shell.execute_reply":"2025-06-21T13:03:30.176613Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Linear Regression with PCA**\n","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2, random_state=42)\n\n# Train model\nlr = LinearRegression()\nlr.fit(X_train, y_train)\n\n# Predict\ny_pred = lr.predict(X_test)\n\n# Evaluate\nmse = mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(mse)\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"RMSE: {rmse:.2f}\")\nprint(f\"RÂ² Score: {r2:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T13:04:15.413948Z","iopub.execute_input":"2025-06-21T13:04:15.414512Z","iopub.status.idle":"2025-06-21T13:04:15.456039Z","shell.execute_reply.started":"2025-06-21T13:04:15.414487Z","shell.execute_reply":"2025-06-21T13:04:15.455285Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Random Forest with PCA**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\n# Initialize model\nrf = RandomForestRegressor(n_estimators=100, random_state=42)\n\n# Train on PCA features\nrf.fit(X_train, y_train)\n\n# Predict\ny_pred_rf = rf.predict(X_test)\n\n# Evaluate\nmse_rf = mean_squared_error(y_test, y_pred_rf)\nrmse_rf = np.sqrt(mse_rf)\nr2_rf = r2_score(y_test, y_pred_rf)\n\nprint(f\"Random Forest RMSE: {rmse_rf:.2f}\")\nprint(f\"Random Forest RÂ² Score: {r2_rf:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T13:05:20.307431Z","iopub.execute_input":"2025-06-21T13:05:20.307722Z","iopub.status.idle":"2025-06-21T13:05:31.542003Z","shell.execute_reply.started":"2025-06-21T13:05:20.307700Z","shell.execute_reply":"2025-06-21T13:05:31.540923Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **XGBOOST WITH PCA**","metadata":{}},{"cell_type":"code","source":"pip install xgboost\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T13:06:25.564762Z","iopub.execute_input":"2025-06-21T13:06:25.565319Z","iopub.status.idle":"2025-06-21T13:06:30.297215Z","shell.execute_reply.started":"2025-06-21T13:06:25.565292Z","shell.execute_reply":"2025-06-21T13:06:30.296217Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import xgboost as xgb\n\n# Initialize model\nxgb_model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42)\n\n# Train on PCA features\nxgb_model.fit(X_train, y_train)\n\n# Predict\ny_pred_xgb = xgb_model.predict(X_test)\n\n# Evaluate\nmse_xgb = mean_squared_error(y_test, y_pred_xgb)\nrmse_xgb = np.sqrt(mse_xgb)\nr2_xgb = r2_score(y_test, y_pred_xgb)\n\nprint(f\"XGBoost RMSE: {rmse_xgb:.2f}\")\nprint(f\"XGBoost RÂ² Score: {r2_xgb:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T13:06:43.503268Z","iopub.execute_input":"2025-06-21T13:06:43.503660Z","iopub.status.idle":"2025-06-21T13:06:46.719890Z","shell.execute_reply.started":"2025-06-21T13:06:43.503619Z","shell.execute_reply":"2025-06-21T13:06:46.718741Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Random Forest Regressor without PCA**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport numpy as np\n\n# Split data (no PCA)\nX_raw = df_encoded.drop('SalePrice', axis=1)\ny_raw = df_encoded['SalePrice']\n\n# Train-test split\nX_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(X_raw, y_raw, test_size=0.2, random_state=42)\n\n# Train Random Forest on raw features\nrf_raw = RandomForestRegressor(n_estimators=100, random_state=42)\nrf_raw.fit(X_train_raw, y_train_raw)\n\n# Predict\ny_pred_raw = rf_raw.predict(X_test_raw)\n\n# Evaluate\nrmse_raw = np.sqrt(mean_squared_error(y_test_raw, y_pred_raw))\nr2_raw = r2_score(y_test_raw, y_pred_raw)\n\nprint(f\"Random Forest (No PCA) RMSE: {rmse_raw:.2f}\")\nprint(f\"Random Forest (No PCA) RÂ² Score: {r2_raw:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T13:08:59.993879Z","iopub.execute_input":"2025-06-21T13:08:59.994697Z","iopub.status.idle":"2025-06-21T13:09:02.509689Z","shell.execute_reply.started":"2025-06-21T13:08:59.994669Z","shell.execute_reply":"2025-06-21T13:09:02.508962Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Log-Transform the Target Variable** ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Check original distribution\nsns.histplot(df_encoded['SalePrice'], kde=True)\nplt.title(\"Original SalePrice Distribution\")\nplt.show()\n\n# Apply log1p (log(1 + x)) to SalePrice\ndf_encoded['SalePrice_log'] = np.log1p(df_encoded['SalePrice'])\n\n# Check new distribution\nsns.histplot(df_encoded['SalePrice_log'], kde=True, color='orange')\nplt.title(\"Log-Transformed SalePrice Distribution\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T13:11:07.274617Z","iopub.execute_input":"2025-06-21T13:11:07.274930Z","iopub.status.idle":"2025-06-21T13:11:07.833999Z","shell.execute_reply.started":"2025-06-21T13:11:07.274909Z","shell.execute_reply":"2025-06-21T13:11:07.833267Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Feature Engineering**","metadata":{}},{"cell_type":"code","source":"# First calculate 'Age' if it doesn't exist\ndf_encoded['Age'] = df_encoded['YrSold'] - df_encoded['YearBuilt']\n\n# Now safely bin it\ndf_encoded['HouseAgeBin'] = pd.cut(\n    df_encoded['Age'], \n    bins=[0, 10, 50, 100, 150], \n    labels=[\"New\", \"Mid\", \"Old\", \"Historic\"]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T14:09:38.700714Z","iopub.execute_input":"2025-06-21T14:09:38.701039Z","iopub.status.idle":"2025-06-21T14:09:38.708369Z","shell.execute_reply.started":"2025-06-21T14:09:38.701016Z","shell.execute_reply":"2025-06-21T14:09:38.707589Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **USING LIGHT GBM** ","metadata":{}},{"cell_type":"code","source":"pip install lightgbm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T13:20:56.403812Z","iopub.execute_input":"2025-06-21T13:20:56.404119Z","iopub.status.idle":"2025-06-21T13:20:59.687380Z","shell.execute_reply.started":"2025-06-21T13:20:56.404095Z","shell.execute_reply":"2025-06-21T13:20:59.686293Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport numpy as np\n\n# Prepare data\nX_lgb = df_encoded.drop(['SalePrice', 'SalePrice_log'], axis=1)\ny_lgb = df_encoded['SalePrice_log']  # Log target\n\n# Train-test split\nX_train_lgb, X_test_lgb, y_train_lgb, y_test_lgb = train_test_split(X_lgb, y_lgb, test_size=0.2, random_state=42)\n\n# Train LightGBM model\nlgb_model = lgb.LGBMRegressor(n_estimators=1000, learning_rate=0.05, max_depth=-1, random_state=42)\nlgb_model.fit(X_train_lgb, y_train_lgb)\n\n# Predict and revert log transform\ny_pred_lgb_log = lgb_model.predict(X_test_lgb)\ny_pred_lgb_final = np.expm1(y_pred_lgb_log)\ny_test_lgb_final = np.expm1(y_test_lgb)\n\n# Evaluate\nrmse_lgb = np.sqrt(mean_squared_error(y_test_lgb_final, y_pred_lgb_final))\nr2_lgb = r2_score(y_test_lgb_final, y_pred_lgb_final)\n\nprint(f\"LightGBM RMSE: {rmse_lgb:.2f}\")\nprint(f\"LightGBM RÂ² Score: {r2_lgb:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T13:54:45.857217Z","iopub.execute_input":"2025-06-21T13:54:45.857933Z","iopub.status.idle":"2025-06-21T13:54:47.329126Z","shell.execute_reply.started":"2025-06-21T13:54:45.857896Z","shell.execute_reply":"2025-06-21T13:54:47.328340Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **LightGBM Tuning** ","metadata":{}},{"cell_type":"code","source":"from lightgbm import LGBMRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\n# Split data\nX_train_lgb, X_val_lgb, y_train_lgb, y_val_lgb = train_test_split(X_lgb, y_lgb, test_size=0.2, random_state=42)\n\n# Train with fixed n_estimators\nlgb_model = LGBMRegressor(\n    learning_rate=0.03,\n    max_depth=10,\n    num_leaves=50,\n    min_child_samples=10,\n    n_estimators=500,  # fixed value for now\n    random_state=42\n)\n\nlgb_model.fit(X_train_lgb, y_train_lgb)\n\n# Predict and inverse log\ny_val_pred_log = lgb_model.predict(X_val_lgb)\ny_val_pred = np.expm1(y_val_pred_log)\ny_val_true = np.expm1(y_val_lgb)\n\n# Evaluate\nrmse_tuned = np.sqrt(mean_squared_error(y_val_true, y_val_pred))\nr2_tuned = r2_score(y_val_true, y_val_pred)\n\nprint(f\"\\nâ Tuned LightGBM RMSE: {rmse_tuned:.2f}\")\nprint(f\"â Tuned LightGBM RÂ² Score: {r2_tuned:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T13:57:08.761014Z","iopub.execute_input":"2025-06-21T13:57:08.761367Z","iopub.status.idle":"2025-06-21T13:57:09.566980Z","shell.execute_reply.started":"2025-06-21T13:57:08.761344Z","shell.execute_reply":"2025-06-21T13:57:09.566190Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import joblib\n\n# Save model\njoblib.dump(lgb_model, \"lightgbm_house_price_model.pkl\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T14:13:08.571860Z","iopub.execute_input":"2025-06-21T14:13:08.572624Z","iopub.status.idle":"2025-06-21T14:13:08.624647Z","shell.execute_reply.started":"2025-06-21T14:13:08.572598Z","shell.execute_reply":"2025-06-21T14:13:08.624042Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nimport pandas as pd\n\n# Load Kaggle test data\ntest_df = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\")\n\n# Store Ids for submission later\ntest_ids = test_df['Id']\n\n# Confirm shape and features\nprint(\"Test data shape:\", test_df.shape)\nprint(\"First few rows:\")\nprint(test_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T14:23:21.401602Z","iopub.execute_input":"2025-06-21T14:23:21.402044Z","iopub.status.idle":"2025-06-21T14:23:21.429942Z","shell.execute_reply.started":"2025-06-21T14:23:21.402021Z","shell.execute_reply":"2025-06-21T14:23:21.429256Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Drop target from train and store original target separately\ntrain_features = df_encoded.drop(['SalePrice', 'SalePrice_log'], axis=1)\n\n# Concatenate train and test\ncombined = pd.concat([train_features, test_df], axis=0)\n\nprint(\"Combined shape:\", combined.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T14:20:03.946907Z","iopub.execute_input":"2025-06-21T14:20:03.947507Z","iopub.status.idle":"2025-06-21T14:20:03.970692Z","shell.execute_reply.started":"2025-06-21T14:20:03.947482Z","shell.execute_reply":"2025-06-21T14:20:03.969926Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Feature 1: Total Square Footage\ntest_df['TotalSF'] = test_df['1stFlrSF'] + test_df['2ndFlrSF'] + test_df['TotalBsmtSF']\n\n# Feature 2: Total Porch Area\ntest_df['TotalPorchSF'] = (\n    test_df['OpenPorchSF'] +\n    test_df['EnclosedPorch'] +\n    test_df['3SsnPorch'] +\n    test_df['ScreenPorch']\n)\n\n# Feature 3: Age of the house\ntest_df['Age'] = test_df['YrSold'] - test_df['YearBuilt']\n\n# Feature 4: Quality Ã Condition\ntest_df['QualityXCondition'] = test_df['OverallQual'] * test_df['OverallCond']\n\n# Feature 5: House Age Bin\ntest_df['HouseAgeBin'] = pd.cut(\n    test_df['Age'],\n    bins=[0, 10, 50, 100, 150],\n    labels=[\"New\", \"Mid\", \"Old\", \"Historic\"]\n)\n\n# Fill NaNs in binned column\ntest_df['HouseAgeBin'] = test_df['HouseAgeBin'].cat.add_categories(\"Unknown\").fillna(\"Unknown\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T14:23:59.009081Z","iopub.execute_input":"2025-06-21T14:23:59.009817Z","iopub.status.idle":"2025-06-21T14:23:59.020885Z","shell.execute_reply.started":"2025-06-21T14:23:59.009791Z","shell.execute_reply":"2025-06-21T14:23:59.020249Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fill missing values using mode from training data\ntest_df.fillna(df_encoded.mode().iloc[0], inplace=True)\n\n# Confirm no missing values remain\nprint(\"Remaining missing values in test_df:\")\nprint(test_df.isnull().sum().loc[lambda x: x > 0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T14:24:38.440844Z","iopub.execute_input":"2025-06-21T14:24:38.441596Z","iopub.status.idle":"2025-06-21T14:24:38.511063Z","shell.execute_reply.started":"2025-06-21T14:24:38.441569Z","shell.execute_reply":"2025-06-21T14:24:38.510251Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# One-hot encode test_df\ntest_df_encoded = pd.get_dummies(test_df)\n\n# Align the test set's columns with the model's training features\nX_test_kaggle = test_df_encoded.reindex(columns=X_lgb.columns, fill_value=0)\n\n# Confirm shape match\nprint(\"Test input shape after encoding and alignment:\", X_test_kaggle.shape)\nprint(\"Model expected input shape:\", X_lgb.shape[1])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T14:25:01.513887Z","iopub.execute_input":"2025-06-21T14:25:01.514306Z","iopub.status.idle":"2025-06-21T14:25:01.550874Z","shell.execute_reply.started":"2025-06-21T14:25:01.514274Z","shell.execute_reply":"2025-06-21T14:25:01.550224Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Sanity check: ensure columns match\nprint(\"Columns match:\", list(X_test_kaggle.columns) == list(X_lgb.columns))\nprint(\"Test shape:\", X_test_kaggle.shape)\nprint(\"Train shape:\", X_lgb.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T14:26:58.936516Z","iopub.execute_input":"2025-06-21T14:26:58.937069Z","iopub.status.idle":"2025-06-21T14:26:58.941405Z","shell.execute_reply.started":"2025-06-21T14:26:58.937046Z","shell.execute_reply":"2025-06-21T14:26:58.940637Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# 1. Make sure you're passing raw numpy (no column names or dtypes)\nX_test_np = X_test_kaggle.values  # This strips off index/column metadata\n\n# 2. Predict log SalePrice using LightGBM Booster model\ny_test_pred_log = lgb_model.predict(X_test_np)\n\n# 3. Reverse the log transformation\ny_test_pred = np.expm1(y_test_pred_log)\n\n# 4. Create Kaggle submission file\nsubmission = pd.DataFrame({\n    \"Id\": test_ids,\n    \"SalePrice\": y_test_pred\n})\nsubmission.to_csv(\"submission.csv\", index=False)\n\nprint(\"â Final submission.csv file created successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T14:31:47.378137Z","iopub.execute_input":"2025-06-21T14:31:47.378650Z","iopub.status.idle":"2025-06-21T14:31:47.461299Z","shell.execute_reply.started":"2025-06-21T14:31:47.378624Z","shell.execute_reply":"2025-06-21T14:31:47.460519Z"}},"outputs":[],"execution_count":null}]}